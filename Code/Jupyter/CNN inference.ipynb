{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import octafilt3r.filter as o3f\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pipeline.config as conf\n",
    "import pipeline.scale as scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-112.07846872 -101.86949262  -96.17280617 ...  -58.9812725\n",
      "    -60.13743646  -61.95149668]\n",
      "  [ -92.09075843  -85.96212331  -81.96860828 ...  -66.42813554\n",
      "    -60.36534606  -61.96858903]\n",
      "  [ -80.7387277   -76.04074525  -72.43306545 ...  -62.86805655\n",
      "    -61.19527704  -61.2146005 ]\n",
      "  ...\n",
      "  [ -71.07396329  -51.66228852  -53.79138514 ...  -60.73648664\n",
      "    -60.00894919  -55.77278697]\n",
      "  [ -69.98841126  -49.97433937  -49.7568959  ...  -60.24063736\n",
      "    -58.57247969  -58.62413913]\n",
      "  [ -64.91913955  -49.75660271  -46.04863918 ...  -59.64576168\n",
      "    -58.08972493  -56.94516303]]\n",
      "\n",
      " [[ -61.47995462  -48.01947404  -46.1688925  ...  -60.07963354\n",
      "    -59.88114422  -59.61316483]\n",
      "  [ -59.22492021  -49.53146089  -47.15983842 ...  -55.92916647\n",
      "    -61.0897809   -60.63917594]\n",
      "  [ -57.82733408  -52.07931623  -48.55707018 ...  -63.04381432\n",
      "    -61.62077401  -60.83209102]\n",
      "  ...\n",
      "  [ -60.45849406  -55.97000498  -54.70351029 ...  -61.46069836\n",
      "    -61.23335613  -64.92786635]\n",
      "  [ -60.00864956  -58.55187395  -57.00814696 ...  -57.65773629\n",
      "    -57.67078759  -59.89228705]\n",
      "  [ -59.48665559  -61.81261371  -59.76150213 ...  -62.09871125\n",
      "    -60.6767163   -61.30030444]]\n",
      "\n",
      " [[ -59.15555228  -63.75896305  -58.73264032 ...  -63.36319816\n",
      "    -65.68973648  -65.77342312]\n",
      "  [ -58.95229419  -67.55011996  -57.59454635 ...  -65.54918165\n",
      "    -60.5505033   -62.32254004]\n",
      "  [ -58.73908612  -61.79209164  -58.68482042 ...  -64.45996637\n",
      "    -54.74493789  -53.38250579]\n",
      "  ...\n",
      "  [ -69.33715086  -63.11019188  -57.33928723 ...  -62.90182297\n",
      "    -59.99134743  -63.59870994]\n",
      "  [ -65.6334668   -59.96710916  -56.87986283 ...  -62.47179368\n",
      "    -63.13782724  -63.18184399]\n",
      "  [ -63.80491627  -56.73951656  -56.01713043 ...  -63.73535929\n",
      "    -59.85368691  -62.42163804]]\n",
      "\n",
      " [[ -62.55567337  -57.45176496  -58.34091366 ...  -62.76323335\n",
      "    -61.11768786  -61.03836355]\n",
      "  [ -61.30867686  -59.29057569  -60.17842772 ...  -64.8874308\n",
      "    -61.89289979  -57.78396914]\n",
      "  [ -60.12906702  -59.99377825  -61.23389822 ...  -65.8782395\n",
      "    -64.94475398  -63.70801822]\n",
      "  ...\n",
      "  [ -60.72285252  -59.40448565  -63.31960622 ...  -61.01270669\n",
      "    -63.76814536  -65.80655185]\n",
      "  [ -60.92092432  -57.36780538  -59.79446912 ...  -62.22330899\n",
      "    -65.35112022  -64.96290094]\n",
      "  [ -59.75829095  -56.3113699   -60.36871973 ...  -64.33651755\n",
      "    -65.81918973  -66.30930181]]]\n",
      "Predicted class: \"street_music\" with 76 score.\n",
      "----- done. -----\n",
      "1 true predictions\n",
      "0 false predictions\n",
      "test accuracy: 100%\n",
      "error ratio: 0%\n"
     ]
    }
   ],
   "source": [
    "param_dict = conf.open_params()\n",
    "\n",
    "base_path = \"Datasets/UrbanSound8k_augmented/street_music/\"\n",
    "stop_at = 30\n",
    "i = 0\n",
    "true = 0\n",
    "false = 0\n",
    "\n",
    "N4CED = load_model(param_dict[\"CNN_name\"])\n",
    "\n",
    "for file in os.listdir(base_path):\n",
    "\n",
    "    if(i == stop_at):\n",
    "        break\n",
    "\n",
    "    \"\"\"\n",
    "    LOAD DATA\n",
    "    \"\"\"\n",
    "    wav, fs = lr.load(base_path + file, sr=param_dict['fs'], duration=param_dict[\"max_dur\"])\n",
    "\n",
    "    if len(wav) < fs:\n",
    "        continue\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    EXTRACT FEATURES\n",
    "    \"\"\"\n",
    "    feats, fcs = o3f.rolling_oct_bank(\n",
    "        wav,\n",
    "        fs,\n",
    "        param_dict['oct_bw_ratio'],\n",
    "        param_dict['order'],\n",
    "        param_dict['fmax'],\n",
    "        param_dict['fmin'],\n",
    "        param_dict['frame_size'],\n",
    "        param_dict['dec_stages'],\n",
    "        param_dict['dec_ord']\n",
    "    )\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    RESHAPE FEATURES\n",
    "    \"\"\"\n",
    "    df = scale.feats2frames(feats, param_dict['frame_size'], fs)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    SCALE FEATURES\n",
    "    \"\"\"\n",
    "    X, scaler = scale.data_scaler(df)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    RUN MODEL\n",
    "    \"\"\"\n",
    "    p = N4CED.predict(X)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    PROCESS RESULTS\n",
    "    \"\"\"\n",
    "    predicted = param_dict[\"class_map\"][np.argmax(np.mean(p, axis=0))]\n",
    "    print(f'Predicted class: \"{predicted}\" with {int(100 * (p[0][np.argmax(p, 1)][0]))} score.')\n",
    "    if predicted == 'street_music':\n",
    "        true += 1\n",
    "    else:\n",
    "        false += 1\n",
    "    i += 1\n",
    "\n",
    "print('----- done. -----')\n",
    "print(f'{true} true predictions\\n{false} false predictions')\n",
    "print(f'test accuracy: {int((true/i)*100)}%\\nerror ratio: {int((false/i)*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JDA1E~1.TSC\\AppData\\Local\\Temp\\tmp55z4slj7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "745868"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(N4CED)\n",
    "tflite_model = converter.convert()\n",
    "open(param_dict[\"CNN_name\"] + \"/\" + param_dict[\"CNN_name\"] + \"_lite.tflite\", \"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0687a98b0160781757b3b9fa1a867d13e9830e123839aa8f211ed2ece874c462"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
